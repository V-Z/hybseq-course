\documentclass[compress, ucs, xelatex, 11pt, xcolor=x11names, aspectratio=169,
	hyperref={
		bookmarks=true,
		unicode=true,
		colorlinks=true,
		pdftitle={HybSeq course},
		plainpages=false,
		pdfauthor={Vojtech Zeisek},
		pdfsubject={Practical processing of HybSeq target enrichment sequencing data on computing grids like MetaCentrum},
		pdfcreator={XeLaTeX},
		pdfkeywords={BASH, command line, GNU, HybSeq, Linux, MetaCentrum, sequencing shell, target enrichment},
		linkcolor=Turquoise4, % Navigation menu links on pages and in navigation menus
		anchorcolor=DodgerBlue4, % Not in use?
		citecolor=DodgerBlue4, % Not in use?
		filecolor=DodgerBlue4, % Not in use?
		menucolor=Tan4, % Not in use?
		urlcolor=DarkOliveGreen4, % Links with \href and \url
		pdftex},
	url={hyphens, lowtilde} % Allow line breaks within URLs
	]{beamer}

% Theme settings
\usetheme[secheader]{Boadilla}
\usecolortheme{beaver}
\setbeamertemplate{headline} {
	\begin{beamercolorbox}{section in head/foot}
		\insertsectionnavigationhorizontal{\paperwidth}{\hskip0pt plus1fill}{\hskip0pt plus1fill}
	\end{beamercolorbox}
	\begin{beamercolorbox}[ht=2ex, dp=1.125ex]{subsection in head/foot}
		\insertsubsectionnavigationhorizontal{\paperwidth}{}{\hfill\hfill}
	\end{beamercolorbox}
	}
\useinnertheme{circles}

% Fonts Linux Libertine
\usepackage{libertine}

% % Other packages
% \usepackage{multicol}
% \usepackage{tabularx}

% TeX logos
\usepackage{dtk-logos}

% In-line higlighting
\renewcommand{\texttt}[1]{\colorbox{Cornsilk2}{{\ttfamily #1}}}

% Change text color of highlighted text
\renewcommand{\alert}[1]{\textcolor{OrangeRed3}{#1}}

% Syntax higlight
\usepackage{minted}
\usemintedstyle{vim} % Styles are listed by pygmentize -L styles; languages are listed by pygmentize -L lexers
\newminted{bash}{linenos, fontsize=\footnotesize, bgcolor=Cornsilk2, fontfamily=tt, gobble=4, numbersep=-3pt}
\newminted{splus}{linenos, fontsize=\footnotesize, bgcolor=Cornsilk4, fontfamily=tt, gobble=4, numbersep=-3pt}
% Change line number style
\renewcommand{\theFancyVerbLine}{
	\sffamily
	\textcolor{DarkOrchid4}{
		\tiny
		\oldstylenums{
			\arabic{FancyVerbLine}
			}
		}
	}

% Fixing space before and after block of code higlight
\BeforeBeginEnvironment{bashcode}{\vspace{-0.5em}}
\AfterEndEnvironment{bashcode}{\par\vspace{-0.5em}}
\BeforeBeginEnvironment{spluscode}{\vspace{-0.5em}}
\AfterEndEnvironment{spluscode}{\par\vspace{-0.5em}}

% % Fixing space before and after multicols region
% \BeforeBeginEnvironment{multicols}{\vspace{-0.5em}}
% \AfterEndEnvironment{multicols}{\par\vspace{-0.5em}}

% Fixing space before and after itemize region
\BeforeBeginEnvironment{itemize}{\vspace{-0.25em}}
\AfterEndEnvironment{itemize}{\vspace{-0.25em}}

% Default language
\usepackage[main=american]{babel}

% Quotes
\usepackage[autostyle=true, english=american]{csquotes}

% Title page
\author[Vojtěch Zeisek]{\textbf{Vojtěch Zeisek}, Roswitha Elisabeth Schmickl, Tomáš Fér and Luciana Salomon}
\institute[\url{https://trapa.cz/}]{Department of Botany, Faculty of Science, Charles University, Prague\\Institute of Botany, Czech Academy of Sciences, Průhonice\\\url{https://trapa.cz/}, \href{mailto:zeisek@natur.cuni.cz}{zeisek@natur.cuni.cz}}
\title{HybSeq course --- from raw data to species trees}
\subtitle{Practical processing of HybSeq target enrichment sequencing data on computing grids like MetaCentrum --- pre-processing, HybPiper, alignments, gene trees, species trees}
\titlegraphic{\includegraphics[width=1cm]{konsole.png}}
\date{May 26--27, 2022}

\begin{document}

\begin{frame}
	\titlepage
\end{frame}

\begin{frame}[allowframebreaks]{Outline}{Target enrichment for plant/animal systematics --- methodological workshop (MB120C117)}
	\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}{Resources before we start}
	\begin{itemize}
		\item Course \href{https://github.com/V-Z/hybseq-course}{git (slides with all links)} and \href{https://is.cuni.cz/studium/eng/predmety/index.php?do=predmet&kod=MB120C117}{information in SIS} (\href{https://is.cuni.cz/studium/predmety/index.php?do=predmet&kod=MB120C117}{česky})
		\item \alert{Scripts} \url{https://github.com/V-Z/hybseq-scripts} \textbf{will be used in the course} --- main resource to follow
		\item Most of the work is done in Linux/UNIX (macOS,~\ldots) command line, so that good knowledge of work in command line is essential, good starting point can be my Linux and MetaCentrum course \url{https://soubory.trapa.cz/linuxcourse/}
		\item Many tasks are done in R, so that at least basic knowledge of R is needed, good starting point can be my R course \url{https://soubory.trapa.cz/rcourse/}
		\item As \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper} is written in \href{https://www.python.org/}{Python}, so that at least minimal knowledge of this language is advantageous
		\item Processing HybSeq data is computationally demanding (it requires plenty of resources), during the course we use \href{https://www.metacentrum.cz/en/Sluzby/Grid/}{MetaCentrum, Czech National Grid Infrastructure} (\href{https://www.metacentrum.cz/cs/Sluzby/Grid/}{česky}) (slide~\ref{CESNET}), but any computing cluster or powerful desktop (for patient users;-) can be used
	\end{itemize}
\end{frame}

\begin{frame}{HybSeq and its data}
	\begin{itemize}
		\item \href{https://bsapubs.onlinelibrary.wiley.com/doi/full/10.3732/apps.1400042}{HybSeq} combines target enrichment and genome skimming (see lesson by RS) and especially in lager plant genomes it allows to select only $\sim$1000 single/low copy genes
		\item It requires sequencing probes, general or group specific (can be design using pipelines like \href{https://github.com/V-Z/sondovac/wiki}{Sondovač})
		\item From sequencing laboratory we get demultiplexed raw FASTQ files
		\item Steps leading to lists of gene trees require plenty of computing resources and disk space
		\begin{itemize}
			\item Even simple operation can take significant time --- think twice before every step
			\item User can select how much resources provide for each step --- depends on data size and available resources (more resources like CPU and memory will speed up processing)
		\end{itemize}
	\end{itemize}
\end{frame}

\subsection{Test data}

\begin{frame}{Zingiberaceae test data set}
	\begin{itemize}
		\item Family Zingiberaceae has altogether ca. 1600 species throughout tropical Africa, Asia, and the Americas
		\item We selected 34 members from TF's dataset as test data
		\item The probes used for sequencing were introduced in \href{https://journals.sagepub.com/doi/full/10.1177/1176934317742613}{Fér et Schmickl 2018} (reduced)
		\item For data structure see slide~\ref{datastructure}
		\item If you did not yet do so, download data (slide~\ref{datadownload}) --- it can take long time\ldots
	\end{itemize}
% 	\includegraphics[width=\textwidth]{} % TODO Add some photos
\end{frame}

\subsection{Data processing overview}

\begin{frame}[allowframebreaks]{Steps from sequencing files to species trees}
	\begin{enumerate}
		\item Trimming of raw sequencing FASTQ files (removal of adaptors,~\ldots) e.g. by \href{http://www.usadellab.org/cms/?page=trimmomatic}{Trimmomatic}
		\item Deduplication of FASTQ reads e.g. by \href{https://sourceforge.net/projects/bbmap/}{BBMap}
		\begin{itemize}
			\item Not strictly required, duplicates mainly provide wrong insight into real coverage of particular loci
		\end{itemize}
		\item Checking of FASTQ files in \href{https://www.bioinformatics.babraham.ac.uk/projects/fastqc/}{FastQC} or similar tool and removal of low-quality files
		\item Preparing probe reference FASTA file and list of samples for processing by HybPiper
		\item Processing every sample with with \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper} (or alternatively \href{https://github.com/tomas-fer/HybPhyloMaker}{HybPhyloMaker} --- see lessons by TF --- or similar tool)
		\begin{enumerate}
			\item Mapping of FASTQ reads with \href{https://github.com/lh3/bwa}{BWA} to FASTA reference
			\item Distributing (sorting) of reads according to successful hits (using \href{https://www.htslib.org/}{Samtools}) into FASTA files for assembly
			\item Assembly of sorted reads with \href{https://github.com/ablab/spades}{SPAdes}
			\item Alignment of SPAdes contigs against the target sequence
			\begin{itemize}
				\item Contigs are not expected to overlap much
				\item Initial exonerate search is filtered for hits that are above a certain threshold
				\item Contigs that pass this filter are arranged in order along the alignment
				\item All contigs that pass the previous steps are concatenated into a \enquote{supercontig} and the exonerate search is repeated
			\end{itemize}
			\item Search for paralogs --- if SPAdes assembler generates multiple contigs that contain coding sequences representing 75\% of the length of the reference protein, HybPiper will print a warning for that gene
			\item Recovering of the individual sequences
			\item Statistics of the recovery
			\item Cleanup of temporal files (especially SPAdes produces huge amount of data unneeded for further processing)
		\end{enumerate}
		\item Statistics of sequence lengths in all samples and more information about recovered contigs
		\item Creation of heatmaps (using \href{https://www.r-project.org/}{R} and packages \href{https://cran.r-project.org/package=gplots}{gplots} and \href{https://cran.r-project.org/package=heatmap.plus}{heatmap.plus}, or \href{https://cran.r-project.org/package=ggplot2}{ggplot2} and \href{https://cran.r-project.org/package=reshape2}{reshape2})
		\item Retrieve of sequences of exons, introns and supercontigs for all samples
		\item Alignment of all contigs (e.g. by \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT}; or \href{https://www.drive5.com/muscle/}{MUSCLE}, \href{http://www.clustal.org/}{Clustal},~\ldots{ }e.g. using \href{https://www.r-project.org/}{R} and packages \href{https://cran.r-project.org/package=ape}{ape} and/or \href{https://cran.r-project.org/package=ips}{ips})
		\begin{itemize}
			\item All alignments must be trimmed --- columns/rows with too much missing data (e.g. beginning and end of the alignment) must be removed (e.g. using \href{https://www.r-project.org/}{R} and package \href{https://cran.r-project.org/package=ape}{ape})
			\item It is also useful to create simple NJ tree graphical check of alignment (e.g. using \href{https://www.r-project.org/}{R} and package \href{https://cran.r-project.org/package=ape}{ape})
		\end{itemize}
		\item Sorting of alignments, statistics of their length and quality, discarding of poor (too short, too few individuals, too few variable positions,~\ldots) alignments
		\item Reconstruction of gene trees from all aligned contigs (e.g. using \href{http://www.iqtree.org/}{IQ-TREE}, or \href{https://github.com/stamatak/ExaML}{ExaML}, \href{https://nbisweden.github.io/MrBayes/}{MrBayes}, \href{http://www.atgc-montpellier.fr/phyml/}{PhyML}, \href{https://github.com/amkozlov/raxml-ng}{RAxML-NG},~\ldots)
		\item Post-processing of gene trees
		\begin{itemize}
			\item Identification, inspection and possible removal of gene trees with significantly different topology (e.g. by \href{https://www.r-project.org/}{R} and packages \href{https://cran.r-project.org/package=ape}{ape} and \href{https://cran.r-project.org/package=kdetrees}{kdetrees}; \href{https://github.com/uym2/TreeShrink}{TreeShrink}, etc.)
			\item Comparison of gene trees (e.g. heatmaps and PCoA by \href{https://www.r-project.org/}{R} and packages \href{https://cran.r-project.org/package=ade4}{ade4}, \href{https://cran.r-project.org/package=ape}{ape}, \href{https://cran.r-project.org/package=distory}{distory}, \href{https://cran.r-project.org/package=phytools}{phytools})
			\item Comparison of (several) (species) trees (e.g.by \href{https://www.r-project.org/}{R} and packages \href{https://cran.r-project.org/package=ape}{ape} or \href{https://cran.r-project.org/package=phytools}{phytools})
		\end{itemize}
		\item Construction of species trees (e.g. by \href{https://github.com/smirarab/ASTRAL}{ASTRAL-III} or \href{https://github.com/pranjalv123/ASTRID}{ASTRID-2})
		\begin{itemize}
			\item Comparison of species tree and gene trees (e.g. by \href{https://bitbucket.org/blackrim/phyparts}{phyparts} and \href{https://github.com/mossmatters/MJPythonNotebooks}{MJPythonNotebooks})
		\end{itemize}
		\item Phylogenetic networks (e.g. by \href{https://bioinfocs.rice.edu/PhyloNet}{PhyloNet})
		\item And more\ldots
	\end{enumerate}
	\vfill
	\begin{block}{Note\ldots}
		\begin{itemize}
			\item This general scheme can be significantly altered\ldots
			\item There are plenty of technical as well as biological problems (HGT, ILS,~\ldots) and new software keep being developed\ldots
			\item Much more analysis possible\ldots
		\end{itemize}
	\end{block}
	\vfill
\end{frame}

\subsection{Software needed}

\begin{frame}[allowframebreaks]{List of software used during the course}
	\begin{itemize}
		\item \href{https://github.com/smirarab/ASTRAL}{ASTRAL} (see lesson by TF) --- species trees from gene trees
		\item BASH 4 or later and GNU core utils (\enquote{Linux command line})
		\item \href{https://sourceforge.net/projects/bbmap/}{BBMap} --- deduplication of FASTQ
		\item \href{https://blast.ncbi.nlm.nih.gov/Blast.cgi?PAGE_TYPE=BlastDocs&DOC_TYPE=Download}{BLAST+} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://github.com/lh3/bwa}{BWA} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://www.wsi.uni-tuebingen.de/lehrstuehle/algorithms-in-bioinformatics/software/dendroscope/}{Dendroscope} --- visualize outputs of \href{https://bioinfocs.rice.edu/PhyloNet}{PhyloNet}
		\item \href{https://www.ebi.ac.uk/about/vertebrate-genomics/software/exonerate}{Exonerate} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://www.gnu.org/software/parallel/}{GNU Parallel} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper} and in BASH scripts)
		\item \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper} --- recovering genes from targeted sequence capture data
		\item \href{http://www.iqtree.org/}{IQ-TREE} --- gene trees
		\item \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT} --- alignment
		\item \href{https://github.com/mossmatters/MJPythonNotebooks}{MJPythonNotebooks} (used by \href{https://bitbucket.org/blackrim/phyparts}{phyparts})
		\item \href{https://bioinfocs.rice.edu/PhyloNet}{PhyloNet} --- phylogenetic networks
		\item \href{https://bitbucket.org/blackrim/phyparts}{phyparts} --- comparison of species tree vs. gene trees
		\item \href{https://www.python.org/}{Python 3.6 or later} and \href{https://biopython.org/}{Biopython 1.59 or later} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://github.com/lutteropp/QuartetScores}{QuartetScores} (see lesson by TF) --- support scores for internodes
		\item \href{https://www.r-project.org/}{R 4.0 or later} and packages \href{https://cran.r-project.org/package=ade4}{ade4}, \href{https://cran.r-project.org/package=adegenet}{adegenet}, \href{https://cran.r-project.org/package=ape}{ape}, \href{https://cran.r-project.org/package=corrplot}{corrplot}, \href{https://cran.r-project.org/package=distory}{distory}, \href{https://cran.r-project.org/package=ggplot2}{ggplot2}, \href{https://cran.r-project.org/package=gplots}{gplots}, \href{https://cran.r-project.org/package=heatmap.plus}{heatmap.plus}, \href{https://cran.r-project.org/package=ips}{ips}, \href{https://cran.r-project.org/package=kdetrees}{kdetrees}, \href{https://cran.r-project.org/package=pegas}{pegas}, \href{https://cran.r-project.org/package=phangorn}{phangorn}, \href{https://cran.r-project.org/package=phytools}{phytools} and \href{https://cran.r-project.org/package=reshape2}{reshape2}
		\begin{itemize}
			\item Used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper}, for alignment of contigs, post-processing of alignments, post-processing and comparison of gene trees, etc.
		\end{itemize}
		\item \href{https://www.htslib.org/}{Samtools} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://github.com/ablab/spades}{SPAdes} (used by \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper})
		\item \href{https://github.com/uym2/TreeShrink}{TreeShrink} --- detection of outlier long branches in collections of phylogenetic trees
		\item \href{http://www.usadellab.org/cms/?page=trimmomatic}{Trimmomatic} --- trimming of FASTQ
	\end{itemize}
\end{frame}

\subsection{MetaCentrum computing environment}

\begin{frame}[allowframebreaks]{CESNET and MetaCentrum}
	\label{CESNET}
	\begin{itemize}
		\item \href{https://www.cesnet.cz/?lang=en}{CESNET} (\href{https://www.cesnet.cz/}{česky}) is organization of Czech universities, Academy of Science and other organizations taking care about Czech backbone Internet, one of world leading institutions of this type
		\item CESNET provides various \href{https://www.cesnet.cz/services/?lang=en}{services} (\href{https://www.cesnet.cz/sluzby/}{česky})
		\begin{itemize}
			\item Massive computations --- \href{https://www.cesnet.cz/services/massive-computations-metacentrum/?lang=en}{MetaCentrum} (\href{https://www.cesnet.cz/sluzby/metacentrum/}{česky}) --- \alert{this we need to process our HybSeq data}
			\item Large \href{https://www.cesnet.cz/services/data-storage/?lang=en}{data storage} (\href{https://www.cesnet.cz/sluzby/datova-uloziste/}{česky}) --- \alert{this we can use to store our HybSeq data}
			\item And \href{https://www.cesnet.cz/services/?lang=en}{much more} (\href{https://www.cesnet.cz/sluzby/}{česky})\ldots
			\item See also my course \url{https://soubory.trapa.cz/linuxcourse/linux_bash_metacentrum_course.pdf} (chapter \enquote{MetaCentrum})
		\end{itemize}
		\item Information about data storage \url{https://du.cesnet.cz/en/start} (\href{https://du.cesnet.cz/cs/start}{česky}) contains detailed usage instructions
		\item Information about MetaCentrum \url{https://www.metacentrum.cz/en/} (\href{https://www.metacentrum.cz/cs/}{česky})
		\item Most of practical information for users are at wiki \url{https://wiki.metacentrum.cz/wiki/Main_Page} (\href{https://wiki.metacentrum.cz/wiki/Hlavn\%C3\%AD_strana}{česky})
		\item To start work see at least \href{https://wiki.metacentrum.cz/wiki/Categorized_list_of_topics}{list of topics} (\href{https://wiki.metacentrum.cz/wiki/Rozcestnik}{česky}), \href{https://wiki.metacentrum.cz/wiki/Computational_services_overview}{overview} (\href{https://wiki.metacentrum.cz/wiki/Prehled_vypocetnich_sluzeb}{česky}), \href{https://wiki.metacentrum.cz/wiki/Beginners_guide}{beginers guide} (\href{https://wiki.metacentrum.cz/wiki/Pruvodce_pro_zacatecniky}{česky}) and \href{https://wiki.metacentrum.cz/wiki/Working_with_data}{work with data} (\href{https://wiki.metacentrum.cz/wiki/Prace_s_daty}{česky})
		\item Of course, good knowledge of work in Linux command line (BASH) is needed\ldots
	\end{itemize}
	\vfill
	\begin{alertblock}{MetaCentrum vs. other clusters\ldots}
		I show processing on MetaCentrum Czech National Grid Infrastructure, as it is readily available, well maintained and contains all needed applications, but it's possible to use any computing cluster in similar way (the scripts are easily modifiable).
	\end{alertblock}
	\vfill
\end{frame}

\begin{frame}{MetaCentrum}
	\begin{itemize}
		\item Find all needed information at \url{https://wiki.metacentrum.cz/wiki/Main_Page} (\href{https://wiki.metacentrum.cz/wiki/Hlavn\%C3\%AD_strana}{česky})
		\item Current state and usage as available at \url{https://metavo.metacentrum.cz/}
		\item Manage your user account at \url{http://metavo.metacentrum.cz/en/myaccount/} (\href{https://metavo.metacentrum.cz/cs/myaccount/}{česky})
		\item Personal view on actual resources and running tasks is at \url{https://metavo.metacentrum.cz/pbsmon2/person}
		\item List of available applications \url{https://wiki.metacentrum.cz/wiki/Kategorie:Applications}
		\item It has several \href{https://wiki.metacentrum.cz/wiki/Frontend}{front ends} (\href{https://wiki.metacentrum.cz/wiki/Celni_uzel}{česky}) where users log, various \href{https://wiki.metacentrum.cz/wiki/Working_with_data}{storages} (\href{https://wiki.metacentrum.cz/wiki/Prace_s_daty}{česky}), and thousands of computers (nodes) doing the calculations --- they are not accessed directly to run task
		\item Most of computers are running \href{https://www.debian.org/}{Debian GNU/Linux}
	\end{itemize}
\end{frame}

\begin{frame}{Basic workflow}
	\begin{center}
		\includegraphics[height=5.5cm]{grid_graphics.jpg}
	\end{center}
	\begin{flushright}
		From \href{https://wiki.metacentrum.cz/wiki/Beginners_guide}{Beginners guide} (\href{https://wiki.metacentrum.cz/wiki/Pruvodce_pro_zacatecniky}{česky})
	\end{flushright}
\end{frame}

\begin{frame}[fragile]{Launching of tasks}
	\begin{itemize}
		\item \url{https://wiki.metacentrum.cz/wiki/About_scheduling_system}
		\item Personal view \url{https://metavo.metacentrum.cz/pbsmon2/person} has nice overview of available resources and tasks and allows comfortable construction of submission command
	\end{itemize}
	\vfill
	\begin{bashcode}
    # We will run up to 5 days (120 h), require one physical
    # computer with 8 CPU threads, 24 GB of RAM, 10 GB of disk
    # space and we get all information mails
    qsub -l walltime=120:0:0 -l select=1:ncpus=8:mem=24gb:
      scratch_local=10gb -m abe metacentrum.sh
    # Check how the task is running (above web) and
    qstat -u $USER # Information about $USER's jobs
    qstat 123456789 # The task ID is available from qstat
    qstat -f 123456789 # Print a lot of details
    qdel 123456789 # Terminate scheduled or running task
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Key MetaCentrum commands}
	\begin{itemize}
		\item MetaCentrum is \enquote{just} normal Linux server --- work as usually
		\item Command \texttt{module} loads/unloads selected \href{https://wiki.metacentrum.cz/wiki/Kategorie:Applications}{application}
		\item Tasks (BASH scripts) are submitted for computing by \texttt{qsub} --- the script must copy the data into \texttt{\$SCRATCHDIR} and do all calculations there
		\begin{itemize}
			\item It has plenty of options how to specify requirements (see \href{https://wiki.metacentrum.cz/wiki/About_scheduling_system}{help})
		\end{itemize}
		\item Queued and running jobs can be seen by \texttt{qstat -u \$USER} (\texttt{qstat} has much more options) and any job can be terminated by \texttt{qdel 123456789} (number from \texttt{qstat})
	\end{itemize}
	\vfill
	\begin{bashcode}
    module avail XXX # List available modules for XXX
    module add <TAB><TAB> # Load some module
    module list # List of currently loaded modules
    module rm XXX # Unload selected module
    qstat -w -n -1 -u $USER -t -p -a @cerit-pbs.cerit-sc.cz
      @elixir-pbs.elixir-czech.cz @meta-pbs.metacentrum.cz # All jobs for $USER
	\end{bashcode}
\end{frame}

\begin{frame}{Running R tasks on MetaCentrum}
	\begin{itemize}
		\item There are only some R packages, to get more create own package library and use it in scripts (see e.g. \texttt{/software/R/4.0.0/gcc/lib/R/library/})
		\item \alert{Be careful about paths!}
		\item In the \texttt{metacentrum.sh} script load R \texttt{module add R-4.0.0-gcc} and start there R script as usually \texttt{R CMD BATCH script.r}
	\end{itemize}
	\begin{enumerate}
		\item Login to selected front node via SSH
		\item Create somewhere new directory for R packages \texttt{mkdir rpkgs} (or use default \texttt{$\sim$/R/})
		\item Start R \texttt{R} and install \textbf{all} R packages needed for the task --- install them into the \texttt{rpkgs} directory \texttt{install.packages(pkgs=\ldots, lib="rpkgs")}
		\item In the R script \texttt{*.r} load the packages from the \texttt{rpkgs} directory \texttt{library(package=\ldots, lib.loc="/storage/\ldots/rpkgs")}
		\item Ensure all needed outputs are saved from the R script
	\end{enumerate}
\end{frame}

\section{Data preprocessing}

\begin{frame}[fragile]{Data download}
	\label{datadownload}
	\begin{itemize}
		\item MetaCentrum storages have sometimes too limited quota for such a large data --- see your \href{https://metavo.metacentrum.cz/en/myaccount/kvoty}{quotas} (\href{http://metavo.metacentrum.cz/cs/myaccount/kvoty}{česky}), details on wiki \href{https://wiki.metacentrum.cz/wiki/Quotas}{wiki}, (\href{https://wiki.metacentrum.cz/wiki/Kvoty}{česky})
		\item The \href{https://github.com/V-Z/hybseq-scripts}{pipeline} produce a lot of data (especially \href{https://github.com/mossmatters/HybPiper/}{HybPiper}, but gene trees can be also large) --- ensure to have enough space to store everything
		\begin{itemize}
			\item Especially \textbf{HybPiper produces a lot of files} --- \alert{user may reach quota for number of files}, not necessarily (only) amount of data
		\end{itemize}
	\end{itemize}
	\begin{bashcode}
    # Login to any MetaCentrum front end
    ssh USER@tilia.ibot.cas.cz # Or any other front end
    # Download the data
    wget https://botany.natur.cuni.cz/zeisek/hybseq_hybpiper_course.zip
    # Unpack it
    unzip hybseq_hybpiper_course.zip
	\end{bashcode}
	\begin{itemize}
		 \item The archive contains input raw data, their complete processing by HypPiper, alignments and gene trees; HybPiper itself, used HybSeq scrips, reference,~\ldots
	\end{itemize}
\end{frame}

\begin{frame}{Scripts and other resources to process the data}
	\begin{itemize}
		\item The archive \texttt{hybseq\_hybpiper\_course.zip} contains\ldots
		\begin{itemize}
			\item \texttt{bin/HypPiper} --- \href{https://github.com/mossmatters/HybPiper/}{HybPiper}, version 1.3 with minor edits (see further)
			\item \texttt{hybseq} --- \href{https://github.com/V-Z/hybseq-scripts}{HybSeq scripts} with installed \textbf{R} packages needed for HybPiper and FASTA reference for HybPiper
			\item \texttt{zingiberace\_hybseq\_course} --- Test data (see following slides)
		\end{itemize}
	\end{itemize}
	\begin{alertblock}{Do not blindly copy-paste commands\ldots}
		\alert{Commands show typical way how to proceed, but should not be using without understanding, and other ways how to work are possible\ldots}{ }Command and submission scripts also \textbf{do require} edits prior launching them.
	\end{alertblock}
\end{frame}

\subsection{General data structure}

\begin{frame}[fragile]{Test data directory structure I}
	\label{datastructure}
	\begin{bashcode}
    ├── bin # Place for various BASH scripts, user SW, ...
    I   └── HybPiper # HybPiper Python and R scripts
    ├── hybseq # BASH scripts to process the data
    I   ├── bin # Scripts themselves
    I   ├── ref # References for HybPiper
    I   ├── rpackages # R library with installed R packages
    └── zingiberace_hybseq_course # Data
        ├── 1_data # Sequencing libraries
        I   ├── lib_01 # Sequencing library 1
        I   I   ├── 0_data # Raw FASTQ sequences
        I   I   ├── 1_trimmed # Trimmed FASTQ sequences
        I   I   ├── 2_dedup # Deduplicated FASTQ sequences
        I   I   └── 3_qual_rep # FastQC quality reports
        I   └── lib_02 # Possible sequencing library 2
        I       ├── 0_data # Raw FASTQ sequences
        I       ├... # Same structure as lib_01...
        ...     ... # Next slide...
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Test data directory structure II}
	\begin{bashcode}
        ... # Previous slide...
        ├── 2_seqs # Outputs of HybPiper
        I   ├── Calathea_crotalifera_S401.dedup # Sample output dir
        I   I   ├── Assembly_1 # Gene output directory
        I   I   ├── ... # More gene output directories...
        I   I   └── Assembly_10014 # Gene output directory
        I   ├── ... # More samples...
        I   └── Zingiber_citriodorum_S171.dedup # Sample output dir
        I       ├── Assembly_1 # Gene output directory
        I       ├── # More gene output directories...
        I       └── Assembly_10014 # Gene output directory...
        ├── 3_aligned # Aligned contigs
        I   ├── exons # Aligned exons
        I   ├── introns # Aligned introns
        I   └── supercontigs # Aligned supercontigs
        ... # Next slide...
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Test data directory structure III}
	\begin{bashcode}
        ... # Previous slide...
        ├── 4_gene_trees # Reconstructed gene trees
        I   ├── exons # Gene trees of exons
        I   ├── introns # Gene trees of introns
        I   └── supercontigs # Gene trees of supercontigs
        I   # Possibly create some substructure for outputs of kdetrees,
        I   # TreeShrink and another gene trees filtration... e.g.
        I   # mkdir {exons,introns,supercontigs}_{0_trees,1_unfiltered,
        I   #   2_pcoa_kdetrees,3_treeshrink}
        I   # To keep everything sorted
        └── 5_species_trees # Processing of the trees
            ├── # Outputs of various analysis like ASTRAL...
            ... # More downstream analysis...
	\end{bashcode}
	\begin{itemize}
		\item Of course, every user can figure different directory structure, but HybSeq produces a lot of data and plenty of software packages are used, so keep some logical structure\ldots
	\end{itemize}
\end{frame}

\subsection{HybSeq scripts}

\begin{frame}[fragile]{Getting HybSeq scripts}
	\begin{itemize}
		\item See \url{https://github.com/V-Z/hybseq-scripts}
		\item Either unpack it from \href{https://botany.natur.cuni.cz/zeisek/hybseq_hybpiper_course.zip}{hybseq\_hybpiper\_course.zip} or install as follows:
	\end{itemize}
	\begin{bashcode}
    # Clone repository with scripts into "hybseq" directory
    cd && git clone https://github.com/V-Z/hybseq-scripts.git hybseq
    # Install all needed R packages
    cd hybseq/ # Go to hybseq directory
    module add R-4.0.0-gcc # Load R module
    R # Start R and install needed packages:
	\end{bashcode}
	\begin{spluscode}
    install.packages(pkgs=c("ape", "ggplot2", "gplots", "heatmap.plus", "ips",
      "reshape2"), lib="rpackages", repos="https://mirrors.nic.cz/R/",
      dependencies="Imports")
    # As heatmap.plus was archived in CRAN recently, possibly install it like
    install.packages(pkgs="https://cran.r-project.org/src/contrib/Archive/
      heatmap.plus/heatmap.plus_1.3.tar.gz", lib="rpackages", repos=NULL)
	\end{spluscode}
\end{frame}

\subsection{Trimming and deduplication}

\begin{frame}{Trimming and deduplication}
	\begin{itemize}
		\item Raw demultiplexed FASTQ sequences must be trimmed (sequencing adaptors removed,~\ldots) and should be deduplicated (removal of artificial duplicates to get correct statistics of coverage)
		\item There are plenty of software packages available, \href{http://www.usadellab.org/cms/?page=trimmomatic}{Trimmomatic} use to be used for trimming and e.g. \href{https://sourceforge.net/projects/bbmap/}{BBMap} for deduplication
		\item Usually, libraries are processed as they are delivered from sequencing company
		\item Quality of all FASTQ files should be checked by e.g. \href{https://www.bioinformatics.babraham.ac.uk/projects/fastqc/}{FastQC}
		\item It is practical to obtain simple statistics --- number of sequences in original files, after trimming and after deduplication
		\item Low quality files should be discarded\ldots
		\item Everything can be easily coded into simple BASH script processing all files (see following slides)
	\end{itemize}
\end{frame}

\begin{frame}{Scripts to trim and deduplicate FASTQ sequences}
	\begin{itemize}
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_1\_qsub.sh}
		\begin{itemize}
			\item Submits via \texttt{qsub} script \texttt{$\sim$/bin/hybseq\_1\_prep\_2\_run.sh} for calculation
			\item Variables \texttt{WORKDIR} and \texttt{DATADIR} must point to correct existing location --- script contains settings for running following script
			\item If changing parameters for \texttt{hybseq\_1\_prep\_2\_run.sh}, parameters for \texttt{qsub} must be changed accordingly
			\item The script is started multiple times to process all sequencing libraries
		\end{itemize}
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_2\_run.sh}
		\begin{itemize}
			\item See \texttt{./hybseq\_1\_prep\_2\_run.sh -h} for usage help
			\item Script checks if all needed parameters and tools are available and in simple \texttt{for} loop trimms all sequences (one by one), deduplicates them, does quality checking, prints simple statistics, and prepares list of samples for HybPiper
		\end{itemize}
		\item Output is prepared as input for HybPiper itself
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Submission of hybseq\_1\_prep\_1\_qsub.sh}
	\begin{itemize}
		\item Pre-processing data for HybPiper
		\item \alert{\texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_1\_qsub.sh} must be edited before submission via \texttt{qsub}}
		\item After it runs for a while (everything had been copyied to the computing node), it is possible to change \texttt{DATADIR} and submit processing of the second library
	\end{itemize}
	\begin{bashcode}
    # After edition of WORKDIR and DATADIR run
    qsub -l walltime=12:0:0 -l select=1:ncpus=4:mem=48gb:
      scratch_local=100gb -m abe ~/hybseq/bin/hybseq_1_prep_1_qsub.sh
    # Or similar command
    # Monitor running $USER's tasks with details
    qstat -w -n -1 -u $USER # Last column contains machine name
    # See your processes running the machine (from above list)
    ssh exec_node "ps ux" # Replace exec_host by hostname!
	\end{bashcode}
\end{frame}

\begin{frame}{Trimm and deduplicate all FASTQ files}
	\begin{exampleblock}{Tasks to pre-process FASTQ data for HybPiper}
			\begin{enumerate}
				\item Inspect \texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_1\_qsub.sh} and \texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_2\_run.sh} and be sure to understand what the scripts do, including syntax used.
				\item Edit declarations of variables \texttt{WORKDIR} and \texttt{DATADIR} in \texttt{hybseq\_1\_prep\_1\_qsub.sh} so that they point to correct locations.
				\item Submit via \texttt{qsub} \texttt{hybseq\_1\_prep\_1\_qsub.sh} to process the data and monitor the jobs during processing.
				\item Inspect outputs of \texttt{hybseq\_1\_prep\_2\_run.sh}, including statistics and FASTQ checks. What do they show?
				\item Can you run the task on your computer (desktop or notebook) without \texttt{qsub}? If so, how?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\section{HybPiper}

\begin{frame}{HybPiper}
	\begin{itemize}
		\item See \href{https://github.com/mossmatters/HybPiper/blob/master/README.md}{README} and \href{https://github.com/mossmatters/HybPiper/wiki}{wiki} documentation
		\item HybPiper is currently in transition from version 1.3 to 2.0, course shows version 1.3 as 2.0 is still under development
		\begin{itemize}
			\item Script \texttt{retrieve\_sequences.py} in newest 1.3 release \href{https://github.com/mossmatters/HybPiper/issues/74}{requires} \texttt{Bio.Alphabet}, which was removed from recent \texttt{biopython}, so that we use older version of this script
		\end{itemize}
		\item HybPiper was designed for targeted sequence capture, in which DNA sequencing libraries are enriched for gene regions of interest, especially for phylogenetics
		\item The Piper pipeline starts with high-throughput sequencing reads, and assigns them to target genes using BLASTx/DIAMOND or BWA. The reads are distributed to separate directories, where they are assembled separately using SPAdes. The main output is a FASTA file of the (in frame) CDS portion of the sample for each target region, and a separate file with the translated protein sequence.
		\item Includes commands to extract the intronic regions flanking each exon, and investigate putative paralogs
	\end{itemize}
\end{frame}

\begin{frame}{Overview of HybPiper}
	\begin{center}
		\includegraphics[height=6.5cm]{hybpiper.png}
	\end{center}
\end{frame}

\subsection{Preparing data for HybPiper}

\begin{frame}{Requirements to run HybPiper}
	\begin{itemize}
		\item See \url{https://github.com/mossmatters/HybPiper/} to see software requirements to run HybPiper
		\item It is possible to run HybPiper on your computer (with Linux or macOS), but it requires plenty of CPU and memory and creates huge output directories\ldots
		\item To process multiple files (by \texttt{while} loop or by \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_1\_submitter.sh}) there must be list of sample base names without suffixes like \texttt{*[.\_]R\{1,2\}.f*q*} (here created by \texttt{hybseq\_1\_prep\_2\_run.sh})
		\item Reference bait FASTA file \textbf{must} have sequences named as \texttt{Species\_name-gene\_id} (see \href{https://github.com/mossmatters/HybPiper/wiki\#12-target-file}{help}) (\alert{note} order and dash in between)
		\item \href{https://github.com/mossmatters/HybPiper}{HybPiper} is processing individual files with given baits FASTA sequences --- batch processing must be scripted
	\end{itemize}
\end{frame}

\begin{frame}{Before running HybPiper}
	\begin{itemize}
		\item Directory \texttt{$\sim$/hybseq/ref/} contains prepared reduced bait file \texttt{curcuma\_hybpiper\_renamed\_concat.fasta} (it will be used to process test data)
		\item To run \href{https://github.com/mossmatters/HybPiper}{HybPiper} we need the target reference file above and all required software, and BASH script to process all input files in batch --- see \texttt{hybseq\_2\_hybpiper\_1\_submitter.sh} (submitting via \texttt{qsub} all input files), \texttt{hybseq\_2\_hybpiper\_2\_qsub.sh} (preparing individual job to run) and \texttt{hybseq\_2\_hybpiper\_3\_run.sh} (processing every input file --- doing the job)
	\end{itemize}
\end{frame}

\begin{frame}{Prepare to run HybPiper}
	\begin{exampleblock}{Tasks before running HybPiper}
		\begin{enumerate}
			\item Check \texttt{samples\_list.txt} in \texttt{2\_dedup} output directory of the test data after running \texttt{$\sim$/hybseq/bin/hybseq\_1\_prep\_1\_qsub.sh}, and check how it was created.
			\item Compare \url{https://github.com/tomas-fer/HybPhyloMaker/blob/master/HybSeqSource/curcuma_HybSeqProbes_test.fa} (output of Geneious assembler) and \texttt{curcuma\_hybpiper\_renamed\_concat.fasta} --- see form required by \href{https://github.com/mossmatters/HybPiper/wiki\#12-target-file}{HybPiper}
			\item Do we have everything needed to run \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper}?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\subsection{Processing input files}

\begin{frame}[allowframebreaks]{Understanding how presented scripts run HybPiper}
	\begin{itemize}
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_1\_submitter.sh} goes to directory set by \texttt{DATADIR} variable and for every sample (pair of forward and reverse FASTQ files) listed in \texttt{samples\_list.txt} (variable \texttt{SAMPLES}, created by \texttt{hybseq\_1\_prep\_2\_run.sh}) and submits via \texttt{qsub} individual task for each input sample (thy are processed independently in parallel)
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_run\_2\_hybpiper\_2\_qsub.sh} drives submission and manipulation of processing of each individual file --- it checks if all required data are provided, copy input files to \texttt{SCRATCHDIR}, loads required software modules, runs processing itself by \texttt{hybseq\_2\_hybpiper\_3\_run.sh} and copy results back
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_3\_run.sh} runs all HybPiper steps for individual samples (as submitted by previous scripts)
		\item Outputs of \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_3\_run.sh} should be checked and moved into special directory (\texttt{$\sim$/zingiberace\_hybseq\_course/2\_seqs}) where new list of samples must be created
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_run\_3\_hybpiper\_postprocess\_1\_qsub.sh} can be then used to run \texttt{$\sim$/hybseq/bin/hybseq\_3\_hybpiper\_postprocess\_2\_run.sh} which uses HybPiper to retrieve sequences of exons, introns and supercontigs, and prints statistics and creates heatmaps --- retrieved sequences can then be aligned (see further)
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Submitting jobs to run HybPiper}
	\begin{itemize}
		\item To retrieve probe sequences from every input FASTQ file
		\item \alert{\texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_1\_submitter.sh} must be edited before running it}
		\item After submission of all input files is done, it is possible to change \texttt{DATADIR} and submit processing of the second library
		\item It will start job for every sample, so that output of \texttt{qstat} will notably prolong\ldots
	\end{itemize}
	\begin{bashcode}
    # After edition of HYBPIPDIR, WORKDIR, DATADIR, SAMPLES,
    # BAITFILE and NCPU run simply
    ./hybseq/bin/hybseq_run_2_hybpiper_1_submitter.sh
    # Monitor running $USER's tasks with details
    qstat -w -n -1 -u $USER # Last column contains machine name
    # See your processes running the machine (from above list)
    ssh exec_node "ps ux" # Replace exec_host by hostname!
	\end{bashcode}
\end{frame}

\begin{frame}{Running HybPiper}
	\begin{exampleblock}{Run HybPiper}
		\begin{enumerate}
			\item Inspect scripts \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_1\_submitter.sh}, \texttt{$\sim$/hybseq/bin/hybseq\_run\_2\_hybpiper\_2\_qsub.sh} and \texttt{$\sim$/hybseq/bin/hybseq\_2\_hybpiper\_3\_run.sh} and be sure to understand what they are doing, including syntax used.
			\item In \texttt{$\sim$/bin/HybPiper/} check \texttt{./reads\_first.py -h}.
			\item Edit declarations of variables \texttt{HYBPIPDIR}, \texttt{WORKDIR}, \texttt{DATADIR}, \texttt{SAMPLES} and \texttt{BAITFILE} in \texttt{hybseq\_2\_hybpiper\_1\_submitter.sh} so that they point to correct locations.
			\item Run \texttt{./hybseq\_2\_hybpiper\_1\_submitter.sh} to process sample data.
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\begin{frame}{Other tasks with HybPiper}{For interested students}
	\begin{exampleblock}{HybPiper tasks for advanced users}
		\begin{enumerate}
			\item Think how to process all samples on single computer. Use \texttt{while} BASH loop and feed it by \texttt{samples\_data.txt}. How would such script look like? What had to be changed?
			\item Check requirements of software used by HybPiper (BWA, SPAdes,~\ldots) and think if changing of number of CPU threads and memory would significantly speed up processing of individual files.
			\item See \texttt{man qsub} and think if there is another option how to pass options from \texttt{hybseq\_2\_hybpiper\_1\_submitter.sh} for individual \texttt{qsub} commands (apart of usage of exported variables as is used now).
			\item Think about \href{https://github.com/mossmatters/HybPiper/wiki}{HybPiper} parameters in \texttt{hybseq\_2\_hybpiper\_3\_run.sh}.
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\subsection{Retrieving sequences}

\begin{frame}{After running HybPiper for every sample\ldots}
	\begin{itemize}
		\item Previous step processed by HybPiper every single sample individually and independently
		\item HybPiper postprocessing will retrieve contigs for every exon, intron and supercontig containing all individuals where particular genetic region was found; and do some statistics
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_3\_hybpiper\_postprocess\_1\_qsub.sh} is submitted via \texttt{qsub} and it runs \texttt{$\sim$/hybseq/bin/hybseq\_3\_hybpiper\_postprocess\_2\_run.sh} which uses HybPiper to obtain table of contig lengths, some statistics, heatmaps, and retrieves from individual directores contigs to be aligned
		\item New list of samples for all samples (all libraries) must be prepared (next slide)
		\item R scripts used with HybPiper version 1.3 have plenty of parameters hard coded, possibly use edited versions from \href{https://botany.natur.cuni.cz/zeisek/hybseq_hybpiper_course.zip}{hybseq\_hybpiper\_course.zip}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sorting data after running HybPiper for all samples}
	\begin{itemize}
		\item Outputs of HybPiper are in same directory as where input files were --- outputs from all libraries must be moved into dedicated directory for post-processing and sequence retrieval
		\item \alert{Code below is exemplary and requires edits, as well as script \texttt{$\sim$/hybseq/bin/hybseq\_run\_3\_hybpiper\_postprocess\_1\_qsub.sh}}
	\end{itemize}
	\begin{bashcode}
    # Move from zingiberace_hybseq_course/1_data/lib_01/2_dedup all outputs
    # of HybPiper to zingiberace_hybseq_course/2_seqs/ for next steps
    mv HybPiper.* hybseq_hybpiper.* *.dedup ../../../2_seqs/
    # Create in zingiberace_hybseq_courses/2_seqs new samples_list.txt
    find . -maxdepth 1 -type d | sed 's/^\.\///' | sort | tail -n+2 >
      samples_list.txt
    # Edit HYBPIPDIR, WORKDIR, BAITFILE and DATADIR in
    # ~/hybseq/bin/hybseq_run_3_hybpiper_postprocess_1_qsub.sh
    # When ready, submit task to post-process HybPiper results
    qsub -l walltime=12:0:0 -l select=1:ncpus=1:mem=2gb:scratch_local=100gb
       -m abe ~/hybseq/bin/hybseq_3_hybpiper_postprocess_1_qsub.sh
	\end{bashcode}
\end{frame}

\begin{frame}{Post-processing HybPiper outputs and retrieving contig sequences I}
	\begin{exampleblock}{Tasks to post-process HybPiper outputs I}
		\begin{enumerate}
			\item Inspect \texttt{$\sim$/hybseq/bin/hybseq\_3\_hybpiper\_postprocess\_1\_qsub.sh} and \texttt{$\sim$/hybseq/bin/hybseq\_run\_3\_hybpiper\_postprocess\_2\_run.sh} and be sure to understand what the scripts do, including syntax used.
			\item Edit declaration of variables \texttt{HYBPIPDIR}, \texttt{WORKDIR}, \texttt{BAITFILE} and \texttt{DATADIR} so that they point to correct locations.
			\item Submit via \texttt{qsub} \texttt{$\sim$/hybseq/bin/hybseq\_run\_3\_hybpiper\_postprocess\_1\_qsub.sh} to post-process all HybPiper outputs.
			\item Inspect outputs of, including statistics, heatmaps and log. What do they show?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\begin{frame}{Post-processing HybPiper outputs and retrieving contig sequences II}{For interested students}
	\begin{exampleblock}{Tasks to post-process HybPiper outputs II}
		\begin{enumerate}
			\item Which part does take the longest time on this task? Does this task take plenty of resources (CPU, memory)?
			\item If not satisfied with heatmaps, edit \texttt{R} scripts in \texttt{$\sim$/bin/HybPiper/} and run them manually (can be done in your notebook).
			\item Can you run the task on your computer (desktop in office or notebook) without \texttt{qsub}? If so, how? Can you run the task directly on MetaCentrum front end?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\section{Alignments}

\begin{frame}[allowframebreaks]{Alignment of all contigs}
	\begin{itemize}
		\item All sequences retrieved in the previous step with HybPiper must be aligned (by any aligner)
		\item Alignments must be post-processed
		\begin{itemize}
			\item Rows (individuals) and/or colums (positions within alignment) with more than $\sim$10--20\% of missing data must be removed (e.g. beginning and the end of the alignment)
			\item Too short alignments or alignments with too few variable sites or too few individuals should be removed
			\item Exact thresholds are to be discussed\ldots
		\end{itemize}
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_1\_submitter.sh} goes to directory set by \texttt{DATADIR} variable and for every contig (all \texttt{*.fasta} or \texttt{*.FNA} files) in that directory (retrieved by \texttt{hybseq\_3\_hybpiper\_postprocess\_2\_run.sh}) submits via \texttt{qsub} individual alignment task
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_run\_4\_alignment\_2\_qsub.sh} drives submission and manipulation of processing of each individual file --- it checks if all required data are provided, copy input files to \texttt{SCRATCHDIR}, loads required software modules, runs processing itself by \texttt{hybseq\_4\_alignment\_3\_run.r} \texttt{R} script and copy results back
		\item \texttt{R} script \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_3\_run.r} aligns every input contig with \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT}, trims the alignment, creates NJ tree (NWK and PNG), creates image of alignment and reports alignment details
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_4\_postprocess.sh} is short, can be runned on the front end, it will sort outputs into subdirectories for exons, intron and supercontigs, create statistics of alignments and lists of NJ gene trees
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Submitting alignment jobs}
	\begin{itemize}
		\item To align all retrieved contigs (sequences)
		\item \alert{\texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_1\_submitter.sh} must be edited before running it}
		\item It will start job for every sample, so that output of \texttt{qstat} will be very long (3 jobs --- respective exon, intron and supercontig --- for every probe)\ldots
		\item For small contigs, jobs are very fast
	\end{itemize}
	\begin{bashcode}
    # After edition of WORKDIR and DATADIR run simply
    ./hybseq/bin/hybseq_4_alignment_1_submitter.sh
    # Monitor running $USER's tasks with details
    qstat -w -n -1 -u $USER # Last column contains machine name
    # Something went wrong? Cancel or running or queued tasks by
    qdel $(qstat -u $USER | grep -o "^[0-9]\+" | tr "\n" " ")
	\end{bashcode}
\end{frame}

\begin{frame}{Running alignments}
	\begin{exampleblock}{Run alignments}
		\begin{enumerate}
			\item Inspect scripts \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_1\_submitter.sh}, \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_2\_qsub.sh} and \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_3\_run.r} and be sure to understand what they are doing, including syntax used.
			\item Edit declarations of variables \texttt{WORKDIR} and \texttt{DATADIR} in \texttt{hybseq\_4\_alignment\_1\_submitter.sh} so that they point to correct locations.
			\item Process all \texttt{*.FNA} and \texttt{*.fasta} files.
			\item Monitor progress of the jobs
			\item Inspect outputs (including images) and log files.
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\begin{frame}{Other tasks with alignments}{For interested students}
	\begin{exampleblock}{Alignment tasks for advanced users}
		\begin{enumerate}
			\item Think how to process all samples on single computer. Use \texttt{find} to list all \texttt{*.FNA} and \texttt{*.fasta} files and pass them to \href{https://www.gnu.org/software/parallel/}{GNU Parallel}. How would such script look like? What had to be changed?
			\item Check requirements of \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT} and/or another aligners and think if changing of number of CPU threads and memory would significantly speed up processing of individual files.
			\item In \texttt{hybseq\_4\_alignment\_3\_run.r} replace usage of \href{https://mafft.cbrc.jp/alignment/software/}{MAFFT} by another aligner like e.g. \href{https://www.drive5.com/muscle/}{MUSCLE} or \href{http://clustal.org/}{Clustal}.
			\item Think about parameters for functions \texttt{deleteGaps()}, \texttt{del.rowgapsonly()} and \texttt{del.colgapsonly()}. How do they influence output (\texttt{*.aln.fasta} files)?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\subsection{Sorting alignments}

\begin{frame}{After all alignment jobs are done}
	\begin{itemize}
		\item Results (alignments named \texttt{*.aln.fasta} and other files) are in newly created \texttt{aligned} directory created by \texttt{hybseq\_4\_alignment\_1\_submitter.sh} in \texttt{DATADIR}
		\item Other outputs are images with alignment checks (\texttt{*.aln.check.png} and \texttt{*.aln.png}), NJ trees (\texttt{*.nwk} and \texttt{*.tree.png}), saturation plots (\texttt{*.saturation.png}) and logs (\texttt{*.log} from \texttt{R} and \texttt{HybSeq.alignment.*.[eo]*} from \texttt{qsub})
		\item Outputs should be sorted by \texttt{hybseq\_4\_alignment\_4\_postprocess.sh} --- it requires only path to the \texttt{aligned} directory
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sorting data after running alignments for all samples}
	\begin{itemize}
		\item Outputs of alignments are in directory \texttt{aligned} which was created in the input directory, files with alignments itself are named \texttt{*.aln.fasta}
		\item It should be sorted by \texttt{hybseq\_4\_alignment\_4\_postprocess.sh}
		\item All outputs should be then moved to dedicated directory (cf. slide~\ref{datastructure})
		\item \alert{Code below is exemplary and requires edits}
	\end{itemize}
	\begin{bashcode}
    # Post-process (sort into subdirectories and get simple
    # statistics) all alignments - provide path to directory
    # with aligned files
    ./hybseq/bin/hybseq_4_alignment_4_postprocess.sh
      ~/zingiberace_hybseq_course/2_seqs/aligned | tee
      hybseq_align_postprocess.log
	\end{bashcode}
\end{frame}

\begin{frame}{Post-processing of alignments}
	\begin{exampleblock}{Tasks to post-process alignments}
		\begin{enumerate}
			\item Inspect \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_4\_postprocess.sh} and be sure to understand what the script does, including syntax used.
			\item Run \texttt{$\sim$/hybseq/bin/hybseq\_4\_alignment\_4\_postprocess.sh}  with correct path to post-process all aligned outputs (previous slide).
			\item Inspect outputs, including statistics, images and logs. Open in spreadsheet (e.g. \href{https://www.libreoffice.org/}{LibreOffice Calc}) the \texttt{*.tsv} tables. What do they show?
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\section{Gene trees}

\begin{frame}[allowframebreaks]{Gene trees from all alignments}
	\begin{itemize}
		\item Gene trees must be computed from all aligned sequences
		\item Gene trees must be post-processed
		\begin{itemize}
			\item Trees should be sorted into subdirectories for exons, introns and supercontigs and lists of gene trees created
			\item Trees with significantly different topology must be identified and inspected (and possibly removed) --- this will be later done in \texttt{R}
			\item Long branches within trees must be identified and respective trees inspected --- artificial long branches can be discarded from given trees (e.g. by \href{https://github.com/uym2/TreeShrink}{TreeShrink})
		\end{itemize}
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_1\_submitter.sh} goes to directory set by \texttt{DATADIR} and for every aligned contig (all \texttt{*.aln.fasta} files) in that directory (created in previous step) submits via \texttt{qsub} individual task to reconstruct gene tree
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_2\_qsub.sh} drives submission and manipulation of processing of each individual file --- it checks if all required data are provided, copy input files to \texttt{SCRATCHDIR}, loads required software modules, runs processing itself by \texttt{hybseq\_5\_gene\_trees\_3\_run.sh} and copy results back
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_3\_run.sh} computes gene tree for every input file with \href{http://www.iqtree.org/}{IQ-TREE 2} (see how easily it can be converted for another tree builder, e.g. \href{https://github.com/amkozlov/raxml-ng}{RAxML-NG})
		\item Script \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_4\_postprocess.sh} is short, can be runned on the front end, it will sort outputs into subdirectories for exons, intron and supercontigs and create lists of maximum likelihood and consensus (after bootstrapping) gene trees
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Submitting gene trees jobs}
	\begin{itemize}
		\item To reconstruct gene trees from every aligned and trimmed sequence
		\item \alert{\texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_1\_submitter.sh} must be edited before running it}
		\item It will start job for every sample, so that output of \texttt{qstat} will be very long (3 jobs --- respective exon, intron and supercontig --- for every of $\sim$1000 probes)\ldots
		\item Larger alignments can take long time to compute --- set \texttt{walltime} in \texttt{hybseq\_5\_gene\_trees\_1\_submitter.sh} accordingly
	\end{itemize}
	\begin{bashcode}
    # After edition of WORKDIR and DATADIR run simply
    ./hybseq/bin/hybseq_5_gene_trees_1_submitter.sh
    # Monitor running $USER's tasks with details
    qstat -w -n -1 -u $USER # Last column contains machine name
    # See your processes running the machine (from above list)
    ssh exec_node "ps ux" # Replace exec_host by hostname!
	\end{bashcode}
\end{frame}

\begin{frame}{Running gene trees}
	\begin{exampleblock}{Run gene trees}
		\begin{enumerate}
			\item Inspect scripts \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_1\_submitter.sh}, \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_2\_qsub.sh} and \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_3\_run.sh} and be sure to understand what they are doing, including syntax used.
			\item Edit declarations of variables \texttt{WORKDIR} and \texttt{DATADIR} in \texttt{hybseq\_run\_5\_gene\_trees\_1\_submitter.sh} so that they point to correct locations.
			\item Run it to process all \texttt{*.aln.fasta} files.
			\item Monitor progress of the jobs
			\item Inspect outputs and log files.
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\begin{frame}{Other tasks with gene trees}{For interested students}
	\begin{exampleblock}{Gene trees tasks for advanced users}
		\begin{enumerate}
			\item See \href{http://www.iqtree.org/doc/Command-Reference}{IQ-TREE help}, check its parameters in \texttt{hybseq\_5\_gene\_trees\_3\_run.sh} and think about possible changes to fit better your needs.
			\item Think how to process all samples on single computer. Use \texttt{find} to list all \texttt{*.aln.fasta} files and pass them to \href{https://www.gnu.org/software/parallel/}{GNU Parallel}. How would such script look like? What had to be changed?
			\item Check requirements of \href{http://www.iqtree.org/}{IQ-TREE} and/or another tree builder and think if changing of number of CPU threads and memory would significantly speed up processing of individual files.
			\item Replace usage of \href{http://www.iqtree.org/}{IQ-TREE} in \texttt{hybseq\_5\_gene\_trees\_3\_run.sh} by another tree builder like e.g. \href{https://github.com/stamatak/ExaML}{ExaML}, \href{https://nbisweden.github.io/MrBayes/}{MrBayes}, \href{https://github.com/stephaneguindon/phyml}{PhyML} or \href{https://github.com/amkozlov/raxml-ng}{RAxML-NG}.
		\end{enumerate}
	\end{exampleblock}
\end{frame}

\begin{frame}[fragile]{Quick visualization of gene trees I}
	\begin{itemize}
		\item Individual gene trees can be quickly visualized by simple \textbf{R} script processing in \texttt{for} loop each gene tree input file
		\item Adjust code below and save it as \texttt{mltreeplot.r} in directory  with gene trees
	\end{itemize}
	\begin{spluscode}
    library(ape)
    # File names [1] file.aln.fasta.treefile / file.aln.fasta.raxml.support
    fnames <- commandArgs(TRUE)
    tr <- read.tree(file=fnames[1])
    png(filename=fnames[2], width=1200, height=1200, units="px", bg="white")
      plot.phylo(x=tr, type="unrooted", edge.color="blue", edge.width=3,
        cex=1.25)
      title("Maximum-likelihood phylogenetic tree")
      nodelabels(text=tr$node.label, frame="none", col="red")
      edgelabels(text=round(x=tr$edge.length, digits=3), frame="none",
        col="brown", cex=0.75)
      add.scale.bar()
      dev.off()
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Quick visualization of gene trees II}
	\begin{itemize}
		\item Run following \texttt{for} loop to process \texttt{R} script from previous slide to get quick visualization of individual gene trees
		\item Of course, this is very exemplary and especially graphical parameters must be highly adjusted according size of phylogeny etc.
	\end{itemize}
	\begin{bashcode}
    # IQ-TREE
    for L in *.aln.fasta.treefile; do echo "${L}"; R CMD BATCH --no-save
      --no-restore "--args ${L} ${L%.aln.fasta.treefile}.mltree.png"
      mltreeplot.r; done
    # RAxML-NG
    for L in *.aln.fasta.raxml.support; do echo "${L}"; R CMD BATCH --no-save
      --no-restore "--args ${L} ${L%.aln.fasta.raxml.support}.mltree.png"
      mltreeplot.r; done
	\end{bashcode}
\end{frame}

\subsection{Post-processing gene trees}

\begin{frame}{After all gene trees jobs are done}
	\begin{itemize}
		\item Results are in newly created \texttt{trees} directory created by \texttt{hybseq\_5\_gene\_trees\_1\_submitter.sh} in \texttt{DATADIR}
		\begin{itemize}
			\item Records of what IQ-TREE did (\texttt{*.log}) and \texttt{HybSeq*} from \texttt{qsub}
			\item Results are in \texttt{*.iqtree} (IQ-TREE report), maximum likelihood tree is in \texttt{*.treefile} and likelihood distances in \texttt{*.mldist}
			\item Ultrafast bootstrap approximation results contain split support values in \texttt{*.splits.nex}, consensus tree in \texttt{*.contree}, bootstrap trees \texttt{*.ufboot} and likelihood mapping plots in \texttt{*.svg} and \texttt{*.eps}
		\end{itemize}
		\item Outputs should be sorted by \texttt{hybseq\_5\_gene\_trees\_4\_postprocess.sh} --- it requires only path to the \texttt{trees} directory
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Sorting data after running gene trees for all samples}
	\begin{itemize}
		\item Outputs of gene trees are in directory \texttt{trees} which was created in the input directory, files with gene tree itself are named \texttt{*.contree}
		\item It should be sorted by \texttt{hybseq\_5\_gene\_trees\_4\_postprocess.sh}
		\item All outputs should be then moved to dedicated directory (cf. slide~\ref{datastructure})
		\item \alert{Code below is exemplary and requires edits}
	\end{itemize}
	\begin{bashcode}
    # Post-process (sort into subdirectories and get lists of
    # gene trees) all gene trees - provide path to directory
    # with gene trees files
    ./hybseq/bin/hybseq_5_gene_trees_4_postprocess.sh
      ~/zingiberace_hybseq_course/3_aligned/trees | tee
      hybseq_gene_trees_postprocess.log
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Post-processing of gene trees}
	\begin{exampleblock}{Tasks to post-process gene trees}
		\begin{enumerate}
			\item Inspect \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_4\_postprocess.sh} and be sure to understand what the script does, including syntax used.
			\item Run \texttt{$\sim$/hybseq/bin/hybseq\_5\_gene\_trees\_4\_postprocess.sh} with correct path to post-process all gene trees outputs.
			\item Inspect outputs of, including logs. What do they show?
		\end{enumerate}
	\end{exampleblock}
	\begin{itemize}
		\item Now we have gene trees for all alignments --- we can directly construct species tree (using e.g. \href{https://github.com/smirarab/ASTRAL}{ASTRAL-III} or \href{https://github.com/pranjalv123/ASTRID}{ASTRID-2} from lists of trees \texttt{trees\_ml\_*.nwk}), or inspect and compare topologies of gene trees and possibly discard outliers
	\end{itemize}
	\begin{bashcode}
    # Some SW like ASTRAL dislike tree names on the beginning of lines
    # - discard them e.g. by (i.e. keeping only tree topology):
    sed -i 's/^[[:graph:]]\+ //' trees_*.nwk
	\end{bashcode}
\end{frame}

\section{Comparing gene trees}

\begin{frame}{Seeing trees in forest}
	\begin{itemize}
		\item Comparison of gene trees start with identifying trees with significantly different topology
		\item There are several distance matrices allowing compare topological differences among trees (and subsequently plot heatmap, PCoA, etc.)
	\end{itemize}
	\begin{block}{How to recognize artifact and real biologial feature?}
		\begin{itemize}
			\item Without good reference genome it is hard to tell if long branches, weird topologies, etc. are some artifacts or biological reality\ldots
			\item Problems commonly start with low-quality DNA in lab and subsequent high number of missing data
			\item Statistically, most of \enquote{weird} gene trees topologies are rather from technical issues, so that most of people filter them out\ldots
			\item Results can vary according to strictness with trimming raw FASTQ, sensitivity of various HybPiper settings, settings of aligner and tree builder\ldots
		\end{itemize}
	\end{block}
\end{frame}

\subsection{Visualizing differences among trees}

\begin{frame}[allowframebreaks]{Distances comparing trees}
	\begin{alertblock}{Single number to compare each pair of complex topologies?}
		\begin{itemize}
			\item To compare topology of trees, we need some apropriate distance matrix
			\item There is no general agreement which is the best, all have issues\ldots
			\item If the distance matrix is not \href{https://en.wikipedia.org/wiki/Euclidean_distance_matrix}{Euclidean}, we run into another issues\ldots
		\end{itemize}
	\end{alertblock}
	\begin{itemize}
		\item The tasks will be done in \href{https://www.r-project.org/}{R}
		\item Download e.g. \texttt{trees\_ml\_exons.nwk} (or another final list of gene trees) and work in \texttt{R} in your notebook
		\begin{itemize}
			\item Comparing plenty of individual gene trees, finding different topologies, construction of consensual species tree topology
			\item Robinsons-Foulds distance in \texttt{phytools::multiRF}
			\begin{itemize}
				\item The index adds 1~for each difference between pair of trees
				\item Well defined only for fully bifurcating trees --- if not fulfilled, some results might be misleading
				\item Allow comparison of trees created by different methods
				\item If the difference is very close to root, RF value can be large, even there are not much differences in the tree at all --- \texttt{dist.multiPhylo} from package \href{https://CRAN.R-project.org/package=distory}{distory} can be an alternative, although interpretation of that geodesic distance is sometimes not so straightforward as simple logic of RF
			\end{itemize}
			\item Methods implemented in \texttt{ape::dist.topo} allow comparison of trees with polytomies (\texttt{method="PH85"}) or use of squared lengths of internal branches (\texttt{method="score"})
			\item Final matrices are commonly not \href{https://en.wikipedia.org/wiki/Euclidean_distance_matrix}{Euclidean} --- may be problematic for usage in methods like PCA
			\begin{itemize}
				\item Test it with \texttt{ade4::is.euclid}, can be scaled (forced to became Euclidean) by functions like \texttt{quasieuclid} or \texttt{cailliez} in \texttt{ade4} --- carefully, it can damage meaning of the data
				\item We get matrix of pairwise differences among trees (from multiple genes), we need display and analyze it
			\end{itemize}
			\item Set of tools for identifying discordant phylogenetic trees are e.g. in package \href{https://CRAN.R-project.org/package=kdetrees}{kdetrees}
			\item Filtered trees (with removed outlying topologies) are input for further species tree reconstruction method
		\end{itemize}
	\end{itemize}
\end{frame}

% \begin{frame}[fragile]{Preparing lists of trees for import into R}
% 	\begin{itemize}
% 		\item If the trees should be rooted, only trees containing the outgroup should be kept
% 		\item \texttt{trees\_ml\_exons.nwk} is shown as an example, but other trees can be used as well
% 		\item \texttt{grep} will easily keep only trees having outgroup \texttt{o\_purpurascens\_S482}
% 	\end{itemize}
% 	\begin{bashcode}
%     # Extract only trees having particular taxon
%     grep o_purpurascens_S482 trees_ml_exons.nwk > trees_ml_exons.out.nwk
%     # See how many trees were lost
%     wc -l trees_ml_exons.nwk trees_ml_exons.out.nwk
% 	\end{bashcode}
% \end{frame}

\begin{frame}[fragile]{Loading trees into R}
	\begin{spluscode}
    # Load libraries
    library(ape)
    library(ade4)
    library(distory)
    library(gplots)
    library(ggplot2)
    library(kdetrees)
    library(phangorn)
    library(phytools)
    # Set working directory
    setwd("~/dokumenty/vyuka/hybseq/")
    # Load the list of trees
    trees <- read.tree(file="trees_ml_exons.nwk")
    trees # See it
    print(trees, details=TRUE)
	\end{spluscode}
\end{frame}
%     # Root all trees
%     trees <- root.multiPhylo(phy=trees, outgroup="o_purpurascens_S482",
%       resolve.root=TRUE)

\begin{frame}[fragile]{Heatmap of topological distances}
	\begin{itemize}
		\item There are several heatmap functions, try also at least \texttt{heatmap}
		\item Edit settings to fit your needs and preferences
	\end{itemize}
	\begin{spluscode}
    # Compute distance of topological similarities
    trees.d <- dist.topo(x=trees, method="score")
    # Plot the heatmap (package gplots)
    png(filename="trees_dist.png", width=10000, height=10000)
      heatmap.2(x=as.matrix(trees.d), Rowv=FALSE, Colv="Rowv",
        dendrogram="none", symm=TRUE, scale="none", na.rm=TRUE,
        revC=FALSE, col=rainbow(15), cellnote=as.matrix(trees.d),
        notecex=1, notecol="white", trace="none",
        labRow=rownames(as.matrix(trees.d)), labCol=colnames
        (as.matrix(trees.d)), key=FALSE, main="Correlation
        matrix of topographical distances")
      dev.off() # Saves the image
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{PCoA of topological distances I}
	\begin{itemize}
		\item Requires \href{https://en.wikipedia.org/wiki/Euclidean_distance_matrix}{Euclidean distance matrix} (\texttt{is.euclid()})
		\item Non-Euclidean matrices can be forced to became Euclidean by e.g. \texttt{quasieuclid()} or \texttt{cailliez()}
		\item There are plenty of options how to display it
	\end{itemize}
	\begin{spluscode}
    # Test if the distance matrix is Euclidean
    is.euclid(distmat=as.dist(trees.d), plot=TRUE, tol=1e-05)
    # PCoA
    trees.pcoa <- dudi.pco(d=trees.d, scannf=FALSE, nf=5)
    trees.pcoa
    # Plot PCoA
    s.label(dfxy=trees.pcoa$li)
    s.kde2d(dfxy=trees.pcoa$li, cpoint=0, add.plot=TRUE)
    add.scatter.eig(trees.pcoa[["eig"]], 3,1,2, posi="bottomright")
    title("PCoA of matrix of pairwise trees distances")
	\end{spluscode}
\end{frame}

\begin{frame}{PCoA of topological distances II}
	\begin{center}
		\includegraphics[height=6.5cm]{pcoa.png}
	\end{center}
\end{frame}

\subsection{Filtering trees}

\begin{frame}[fragile]{Filtration of PCoA}
	\begin{spluscode}
    trees # See original trees
    # Remove trees identified in the PCoA plot
    trees[c("Assembly_10373", "Assembly_10725")] <- NULL
    trees # See new object
    # Possibly remove trees with too few tips
    print(trees, details=TRUE)
    trees[c(1, 2, 7, 10, 14, 19, 20, 25)] <- NULL
    trees
    # Export filtered trees
    write.tree(phy=trees, file="trees_exons_filtered.nwk")
	\end{spluscode}
	\begin{itemize}
		\item Now you can repeat recalculation of distance matrix and PCoA and possibly remove more trees\ldots{ }--- or use another method like kdetrees (next slide) etc.
		\item Calculation of distance matrix for large tree set can be very time demanding\ldots
		\item See more details in \url{https://soubory.trapa.cz/rcourse/}, chapter \enquote{Trees} and subchapters \enquote{Seeing trees in forest} and \enquote{Comparisons}
	\end{itemize}
\end{frame}

\begin{frame}[fragile]{Kdetrees}
	\begin{itemize}
		\item Finds discordant phylogenetic trees
		\item Produces relative scores --- high are relatively similar to each other, low dissimilar (discordant with the others)
		\item Produces scores, list of passing/discarded trees and graphical outputs
		\item In \texttt{kdetrees()}, \alert{value of \texttt{k} is responsible for threshold for removal of outliers --- play with it}
	\end{itemize}
	\begin{spluscode}
    # Run kdetrees to detect outliers - play with k
    ?kdetrees # See options for kdetrees
    # Remove rare tips
    trees <- lapply(X=trees, FUN=drop.tip, tip=c("Paracostus_paradoxus_S266",
      "Costus_tonkinensis_S268", "Orchidantha_chinensis_S352"))
    class(trees) <- "multiPhylo"
    trees.kde <- kdetrees(trees=trees, k=0.5 distance="dissimilarity",
      topo.only=FALSE, greedy=TRUE)
    # See text results with list of outlying trees
    trees.kde
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Outputs of kdetrees}
	\begin{spluscode}
    # See graphical results
    plot(x=trees.kde)
    hist(x=trees.kde)
    # See removed trees
    plot.multiPhylo(trees.kde[["outliers"]])
    # Save removed trees
    write.tree(phy=trees.kde[["outliers"]], file="trees_outliers.nwk")
    # Save kdetrees report
    write.table(x=as.data.frame(x=trees.kde), file="trees_scores.tsv",
      quote=FALSE, sep="\t")
    # Extract passing trees
    trees.good <- trees[names(trees) %in% names(trees.kde[["outliers"]])
      == FALSE]
    trees.good
    # Save passing trees
    write.tree(phy=trees.good, file="trees_good.nwk")
	\end{spluscode}
\end{frame}

\begin{frame}{Outputs of kdetrees --- graphs}
	\begin{center}
		\includegraphics[height=6.5cm]{kdetrees.png}
	\end{center}
\end{frame}

\begin{frame}[fragile]{TreeShrink}
	\begin{itemize}
		\item Algorithm for detecting abnormally long branches in one or more phylogenetic trees \href{https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4620-2}{Mai et Mirarab 2018}
		\item Requires \href{https://www.r-project.org/}{R} 4.0.X to be installed (e.g. module \texttt{R-4.0.0-gcc})
		\item See \href{https://github.com/uym2/TreeShrink}{more usage options}
	\end{itemize}
	\begin{bashcode}
    # Go to ~/bin directory
    cd ~/bin/ || { mkdir ~/bin && cd ~/bin/; }
    # Download TreeShrink
    git clone https://github.com/uym2/TreeShrink.git
    cd TreeShrink/
    # Install it
    python3 setup.py install --user # Or if using conda
    conda install -c smirarab treeshrink
    # Go to directory with trees_good.nwk and run TreeShrink
    python3 ~/.local/bin/run_treeshrink.py -h # See help
    run_treeshrink.py -t trees_good.nwk -o treeshrink -O exons
    ls -lha treeshrink/ # Results
	\end{bashcode}
\end{frame}

\begin{frame}{Outputs of TreeShrink} % [fragile]
	\begin{itemize}
		\item Output (3 files) is saved into directory (in our case) \texttt{treeshrink}
		\item File \texttt{*.nwk} contains new list of phylogenetic trees in \texttt{NEWICK} which can be then used as an input for any species tree reconstruction software
		\item \texttt{*.txt} files can be bit hard to read
		\begin{itemize}
			\item \texttt{exons.txt} has one line for every tree in the input list and every line contains list of removed tips --- if there is an empty line, no tip was removed from that particular tree; trees are not named, only in same order as in the original input file
			\item \texttt{exons\_summary.txt} contains statistics for affected taxa
		\end{itemize}
		\item \texttt{exons.nwk} can be directly used as input for ASTRAL or so (see also lesson by TF)
	\end{itemize}
% 	\begin{bashcode}
%     # Find out how many times particular sample was removed from the list of
%     # the trees
%     grep -o "\<[[:graph:]]\+\>" trees_good_RS_0.05.txt | sort | uniq -c |
%       sort -r
% 	\end{bashcode}
\end{frame}

\subsection{Species trees}

\begin{frame}[fragile]{Parsimony super tree}
	\begin{itemize}
		\item Parsimony has plenty of implementation, example below is from \texttt{R} package \texttt{phangorn}
		\item Usage, principles and accuracy are more or less same\ldots
	\end{itemize}
	\begin{spluscode}
    # Compute parsimony super tree
    ?superTree # See help first...
    tree.sp <- superTree(tree=trees.good, method="NNI", rooted=TRUE,
      trace=2, start=NULL, multicore=TRUE)
    tree.sp # See details
    # Save parsimony super tree
    write.tree(phy=tree.sp, file="parsimony_sp_tree.nwk")
    # Plot parsimony super tree
    plot.phylo(x=tree.sp, type="phylogram", edge.width=2,
      label.offset=0.01, cex=1.2)
    add.scale.bar()
    # Tune display of the tree...
	\end{spluscode}
\end{frame}
%     # Rooting the species tree
%     tree.sp <- root(phy=tree.sp, outgroup="o_purpurascens_S482",
%       resolve.root=TRUE)

\begin{frame}[fragile]{Other options for species tree estimation in R}
	\begin{itemize}
		\item Similar approach as \texttt{superTree} is implemented in \texttt{phytools::mrp.supertree}
		\item Distance-based tree reconstruction is in \texttt{ape::speciesTree}
		\item Coalescence model handling multiple individuals per species is in \texttt{phangorn::coalSpeciesTree}
	\end{itemize}
	\begin{spluscode}
    # See help for mrp.supertree and coalSpeciesTree
    ?phytools::mrp.supertree
    ?phangorn::coalSpeciesTree
    # All trees must be ultrametric - chronos scale them
    trees.ultra <- lapply(X=trees.good, FUN=chronos, model="correlated")
    class(trees.ultra) <- "multiPhylo"
    # Calculate the species tree
    tree.sp.mean <- speciesTree(x=trees.ultra, FUN=mean)
    tree.sp2 <- mrp.supertree(tree=trees.good, method="optim.parsimony",
      rooted=TRUE)
	\end{spluscode}
\end{frame}

\subsection{Phylogenetic networks}

\begin{frame}[fragile]{Consensus network}
	\begin{itemize}
		\item Available in \texttt{R} package \texttt{phangorn}
		\item Requires same set of tips in all trees
	\end{itemize}
	\begin{spluscode}
    # See help
    ?consensusNet
    # Compute consensus network
    tree.net <- consensusNet(obj=trees.good, prob=0.25)
    # Plot 2D or 3D
    plot(x=tree.net, planar=FALSE, type="2D", use.edge.length=TRUE,
      show.tip.label=TRUE, show.edge.label=TRUE, show.node.label=TRUE,
      show.nodes=TRUE, edge.color="black", tip.color="blue") # 2D
    plot(x=tree.net, planar=FALSE, type="3D", use.edge.length=TRUE,
      show.tip.label=TRUE, show.edge.label=TRUE, show.node.label=TRUE,
      show.nodes=TRUE, edge.color="black", tip.color="blue") # 3D
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Phylonet}
	\begin{itemize}
		\item Requires as input NEXUS file with settings describing \href{https://wiki.rice.edu/confluence/display/PHYLONET/List+of+PhyloNet+Commands}{PhyloNet commands} (see example below) --- e.g. export NEXUS from \texttt{R}
	\end{itemize}
	\begin{bashcode}
    #NEXUS
    BEGIN TREES;
    ... list of trees from trees_good.nwk newick file ...
    # Ever tree starts with:
    Tree TreeID = (tree in NWK)
    ... # All other trees ...
    END;
    BEGIN PHYLONET;
    InferNetwork_MP (all) 1 -b 50 -x 5 -pl 2 -di;
    END;

    # Download binary JAR file (ready to run)
    wget https://bioinfocs.rice.edu/sites/g/files/bxs266/f/kcfinder/files/
      PhyloNet_3.8.2.jar
    java -Xmx8g -jar PhyloNet_3.8.2.jar file.nex | tee file.log
	\end{bashcode}
\end{frame}

\begin{frame}{Running phylonet}
	\begin{itemize}
		\item \href{https://bioinfocs.rice.edu/PhyloNet}{PhyloNet} has various options how to create phylogenetic network
		\item Can be computationally very demanding, running long time
		\item Prepare the list of trees for the NEXUS file e.g. in spreadsheet
		\item The \texttt{PHYLONET} section of the input NEXUS contains settings according to \href{https://wiki.rice.edu/confluence/display/PHYLONET/List+of+PhyloNet+Commands}{list of commands}
		\item TreeID can be completely random, or simple consecutive sequence like GT0001--GT\#\#\#\#
		\item PhyloNet can be computationally very demanding, calculating more than 1--3 reticulations can be unrealistic in terms of time needed\ldots
		\item It does not save output file, the network in special NWK format for \href{https://www.wsi.uni-tuebingen.de/lehrstuehle/algorithms-in-bioinformatics/software/dendroscope/}{Dendroscope} is on the end --- copy it from terminal (after \texttt{Visualize in Dendroscope :}) or log file and save as tiny TXT, which can be opened in \href{https://www.wsi.uni-tuebingen.de/lehrstuehle/algorithms-in-bioinformatics/software/dendroscope/}{Dendroscope}
	\end{itemize}
\end{frame}

\subsection{Comparing trees}

\begin{frame}[fragile]{Installing phyparts and other tools}
	\begin{itemize}
		\item Requires \texttt{maven} and several Python packages, installation can be complicated\ldots
	\end{itemize}
	\begin{bashcode}
    cd ~/bin/
    # Install Phyparts
    git clone https://bitbucket.org/blackrim/phyparts.git
    cd phyparts/
    # Install dependencies
    ./mvn_cmdline.sh
    # Install PhyParts_PieCharts
    git clone https://github.com/mossmatters/MJPythonNotebooks.git
    # Or on MetaCentrum...
    module add phyparts-0.0.1
    # Split list of trees into individual files
    mkdir trees_good
    split -a 4 -d -l 1 trees_good.nwk trees_good/trees_good_
    ls trees_good/
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Producing phyparts and phypartspiecharts.py outputs}
	\begin{bashcode}
    # Remove IQTREE ultrafast bootstrap values from gene trees
    sed -i 's/\/[0-9]\{1,3\}//g' trees_good/trees_*
    # Analysis with phyparts
    java -jar ~/bin/phyparts/target/phyparts-0.0.1-SNAPSHOT-
      jar-with-dependencies.jar --help
    java -jar ~/bin/phyparts/target/phyparts-0.0.1-SNAPSHOT-
      jar-with-dependencies.jar -a 1 -d trees_good -m
      parsimony_sp_tree.nwk -o trees_good_res -s 0.5 -v
    # Copy phypartspiecharts.py to directory with trees
    cp ~/bin/phyparts/MJPythonNotebooks/phypartspiecharts.py .
    # See help for phypartspiecharts.py
    python phypartspiecharts.py --help
    # Pie chart: concordance (blue) top conflict (green),
    # other conflict (red), no signal (gray)
    # Run phypartspiecharts.py to get the graphical output
    python phypartspiecharts.py --svg_name trees_good_res.svg
      parsimony_sp_tree.nwk trees_good_res 6
	\end{bashcode}
\end{frame}

\begin{frame}[fragile]{Comparing two trees --- cophyloplots}
	\begin{itemize}
		\item Slightly different implementation in \texttt{R} packages \texttt{ape} (\texttt{cophyloplot}) and \texttt{phytools} (\texttt{cophylo})
		\item See help pages and play with graphical parameters
	\end{itemize}
	\begin{spluscode}
    # We need 2 column matrix with tip labels
    tips.labels <- matrix(data=c(sort(tree.sp[["tip.label"]]), sort
      (tree.sp2[["tip.label"]])), nrow=length(tree.sp[["tip.label"]]), ncol=2)
    # Draw the tree, play with graphical parameters
    # Click to nodes to rotate them to get better display
    cophyloplot(x=tree.sp, y=tree.sp2, assoc=tips.labels, use.edge.length=
      FALSE, space=60, length.line=1, gap=2, type="phylogram", rotate=TRUE,
      col="red", lwd=1.5, lty=2)
    # Slihtly better display in phytools::cophylo
    trees.cophylo <- cophylo(tr1=tree.sp, tr2=tree.sp2, assoc=tips.labels,
      rotate=TRUE)
    plot.cophylo(x=trees.cophylo, lwd=2, link.type="curved")
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Density tree}
	\begin{itemize}
		\item The trees should be (otherwise plotting works, but may be more ugly) rooted, ultrametric and binary bifurcating
		\item Implementations are in \texttt{phangorn} (\texttt{densiTree}) and \texttt{phytools} (\texttt{densityTree})
	\end{itemize}
	\begin{spluscode}
    is.rooted.multiPhylo(trees.ultra) # rooted
    is.ultrametric.multiPhylo(trees.ultra) # ultrametric
    is.binary.multiPhylo(trees.ultra) # binary bifurcating
    # See help page
    ?phangorn::densiTree
    # Plotting density trees
    densiTree(x=trees.ultra, direction="downwards", scaleX=TRUE,
      col=rainbow(3), width=5, cex=1.5)
    densiTree(x=trees.ultra, direction="upwards", scaleX=TRUE, width=5)
    densiTree(x=trees.ultra, scaleX=TRUE, width=5, cex=1.5)
	\end{spluscode}
\end{frame}

\begin{frame}[fragile]{Different display for multiple trees}
	\begin{itemize}
		\item \texttt{phytools::densiTree} requires same number of tips in all trees
		\item Note various ways how to select trees to display
		\item Nodes of the trees are not rotated (the display might be suboptimal)
	\end{itemize}
	\begin{spluscode}
    # See help page
    ?phytools::densityTree
    # Plotting density trees
    densityTree(trees=c(tree.sp, tree.sp2), fix.depth=TRUE, use.gradient=TRUE,
      alpha=0.5, lwd=4)
    densityTree(trees=trees.ultra, fix.depth=TRUE, use.gradient=TRUE,
      alpha=0.5, lwd=4)
    densityTree(trees=trees.ultra[1:3], fix.depth=TRUE, use.gradient=TRUE,
      alpha=0.5, lwd=4)
    densityTree(trees=trees.ultra[c(2, 4, 6)], fix.depth=TRUE,
      use.gradient=TRUE, alpha=0.5, lwd=4)
	\end{spluscode}
\end{frame}

\section{The end}

\begin{frame}{This is just beginning of long journey\ldots}
	\begin{itemize}
		\item I presented common basic tools how to process HybSeq data and deal with various problems, but new tools keep emerging\ldots
		\item Stay updated and keep trying new tools
		\item The scripts presented are not the only rigid way how to proceed, rather very general guideline, which should be subject of heavy modificcations according to your needs\ldots
	\end{itemize}
\end{frame}

\subsection{The very end}

\begin{frame}{The end}{Our course is over\ldots}
	\begin{center}
		\ldots I~hope it was helpful for You\ldots
		\vfill
		\ldots any feedback is welcomed\ldots
		\vfill
		\ldots happy playing with the data\ldots
		\vfill
		\ldots any final questions?
		\vfill
	\end{center}
	\vfill
	\begin{flushright}
		\begin{tiny}
		\href{https://en.wikipedia.org/wiki/XeTeX}{Typesetting} using \XeLaTeX{ }on \href{https://www.opensuse.org/}{openSUSE} \href{https://en.wikipedia.org/wiki/GNU}{GNU}/\href{https://en.wikipedia.org/wiki/Linux}{Linux} \today
		\end{tiny}
	\end{flushright}
\end{frame}

\end{document}
